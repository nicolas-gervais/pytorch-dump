from sklearn.datasets import load_iris
import torch
from torch.utils.data import Dataset
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

data, labels = load_iris(return_X_y=True)


class IrisDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __getitem__(self, index):
        sample = dict(data=self.X[index], target=self.y[index])
        return sample

    def __len__(self):
        return len(self.X)


iris = IrisDataset(data, labels)

loader = torch.utils.data.DataLoader(iris, batch_size=4, shuffle=True)

device = 'cuda:0' if torch.cuda.is_available() else 'cpu'

example_input, example_label = iter(loader).next()


class DenseNet(nn.Module):
    def __init__(self):
        super(DenseNet, self).__init__()
        self.lin1 = nn.Linear(4, 8)
        self.lin2 = nn.Linear(8, 16)
        self.lin3 = nn.Linear(16, 32)
        self.lin4 = nn.Linear(32, 3)

    def forward(self, x):
        x = F.relu(self.lin1(x))
        x = F.relu(self.lin2(x))
        x = F.relu(self.lin3(x))
        x = F.softmax(self.lin4(x), dim=-1)
        return x


net = DenseNet()

net.to(device)

optimizer = optim.Adam(net.parameters(), lr=0.001)

criterion = nn.CrossEntropyLoss()

for epoch in range(1, 25 + 1):
    running_loss = 0.

    for ix, data in enumerate(loader, 1):
        inputs = data['data'].type(torch.FloatTensor).to(device)
        labels = data['target'].type(torch.LongTensor).to(device)

        optimizer.zero_grad()

        outputs = net(inputs)

        loss = criterion(outputs, labels)
        loss.backward()

        optimizer.step()

        running_loss += loss.item()

        if ix % 5 == 0:
            correct = 0
            total = 0
            with torch.no_grad():
                for data in loader:
                    inputs = data['data'].type(torch.FloatTensor).to(device)
                    labels = data['target'].type(torch.LongTensor).to(device)

                    outputs = net(inputs)

                    _, predicted = torch.max(outputs.data, dim=1)

                    total += labels.size(0)
                    correct += torch.eq(predicted, labels).sum().item()

            print(f'Epoch {epoch:2d} Batch {ix:2d} Loss {running_loss:=6.3f} Acc {correct/total:=5.3%}')
            running_loss = 0.
